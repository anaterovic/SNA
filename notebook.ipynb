{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create --name sna --file environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "postings_1 = pd.read_csv('input/Postings_01052019_15052019.csv', sep=';')\n",
    "postings_2 = pd.read_csv('input/Postings_16052019_31052019.csv', sep=';')\n",
    "votes_1 = pd.read_csv('input/Votes_01052019_15052019.csv', sep=';')\n",
    "votes_2 = pd.read_csv('input/Votes_16052019_31052019.csv', sep=';')\n",
    "follow_ignore = pd.read_csv(\"input/Following_Ignoring_Relationships_01052019_31052019.csv\", sep=\";\")\n",
    "\n",
    "# Merge the two datasets\n",
    "postings = pd.concat([postings_1, postings_2])\n",
    "votes = pd.concat([votes_1, votes_2])\n",
    "\n",
    "votes[\"VoteCreatedAt\"] = pd.to_datetime(votes[\"VoteCreatedAt\"], format=\"%Y-%m-%d %H:%M:%S\").dt.date\n",
    "postings[\"PostingCreatedAt\"] = pd.to_datetime(postings[\"PostingCreatedAt\"], format=\"%Y-%m-%d %H:%M:%S\").dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsetting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering users that interacted at the middle of the interval. Possible future extension: pick time interval instead of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find u-u tuples with their first date of interaction by vote\n",
    "first_contact_vote_pairs = (votes[[\"UserCommunityName\", \"UserCreatedAt\", \"ID_Posting\", \"VoteCreatedAt\"]]\n",
    " .merge(postings[[\"ID_Posting\", \"UserCommunityName\", \"UserCreatedAt\"]], on=[\"ID_Posting\"], how=\"left\")\n",
    " [[\"UserCommunityName_x\", \"UserCommunityName_y\", \"VoteCreatedAt\"]]\n",
    " .sort_values(\"VoteCreatedAt\")\n",
    " .groupby([\"UserCommunityName_x\", \"UserCommunityName_y\"])\n",
    " .first()\n",
    " .reset_index())\n",
    "\n",
    "first_contact_reply_pairs = (postings.dropna(subset=[\"ID_Posting_Parent\"])[\n",
    " [\"UserCommunityName\", \"ID_Posting_Parent\", \"PostingCreatedAt\"]]\n",
    " .merge(postings[[\"ID_Posting\", \"UserCommunityName\"]], left_on=[\"ID_Posting_Parent\"], right_on=[\"ID_Posting\"], how=\"left\")\n",
    " [[\"UserCommunityName_x\", \"UserCommunityName_y\", \"PostingCreatedAt\"]]\n",
    " .sort_values(\"PostingCreatedAt\")\n",
    " .groupby([\"UserCommunityName_x\", \"UserCommunityName_y\"])\n",
    " .first()\n",
    " .reset_index())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a directed relationship: Person x contacted person y. We want to map this unidirectional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bidirectionality(df, on=\"VoteCreatedAt\"):\n",
    "    \"\"\"Here we account for bidirectionality of the contact pairs. The problem is that if user A comments user B's post,\n",
    "     but user B previously commented user A's post we have 2 rows with (eventually) different dates. We take the minimum and leciographycally sort the usernames for enabling joining\"\"\"\n",
    "    inv_df = (df.merge(df, left_on=[\"UserCommunityName_x\", \"UserCommunityName_y\"], right_on=[\"UserCommunityName_y\", \"UserCommunityName_x\"], suffixes=(\"\", \"_inv\"), how=\"left\")\n",
    "    .fillna(pd.to_datetime(\"2050-01-01\", format=\"%Y-%m-%d\").date()))\n",
    "    inv_df[f\"{on}_bidirectional\"] = inv_df[[f\"{on}_inv\",on]].min(axis=1)\n",
    "    inv_df[[\"UserCommunityName_x\", \"UserCommunityName_y\"]] = np.sort(inv_df[[\"UserCommunityName_x\", \"UserCommunityName_y\"]], axis=1)\n",
    "    return inv_df[[\"UserCommunityName_x\", \"UserCommunityName_y\", f\"{on}_bidirectional\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_contact_vote_pairs_bd = apply_bidirectionality(first_contact_vote_pairs, \"VoteCreatedAt\")\n",
    "first_contact_reply_pairs_bd = apply_bidirectionality(first_contact_reply_pairs, \"PostingCreatedAt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fist_contact = (first_contact_reply_pairs_bd.merge(first_contact_vote_pairs_bd, on=[\"UserCommunityName_x\", \"UserCommunityName_y\"], how=\"outer\")\n",
    "    .fillna(pd.to_datetime(\"2050-01-01\", format=\"%Y-%m-%d\").date())) # We set a date in the future to avoid problems with the min function\n",
    "fist_contact[\"first_contact\"] = fist_contact[[\n",
    "    \"PostingCreatedAt_bidirectional\", \"VoteCreatedAt_bidirectional\"]].min(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 5, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_span = fist_contact[\"first_contact\"].max() - fist_contact[\"first_contact\"].min()\n",
    "half_time_span = time_span/2\n",
    "middle = (fist_contact[\"first_contact\"].min() + half_time_span)\n",
    "middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_user_pairs = fist_contact[fist_contact[\"first_contact\"] == middle][[\"UserCommunityName_x\", \"UserCommunityName_y\", \"first_contact\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user pairs can now be viewed as a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_users = pd.concat([subset_user_pairs[\"UserCommunityName_x\"], subset_user_pairs[\"UserCommunityName_y\"]]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/3 of users had contact with someone for the first time in the middle of the interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3341048009020236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_users.nunique() /  pd.concat([votes[\"UserCommunityName\"], postings[\"UserCommunityName\"]]).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a notion of similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Posting similarity\n",
    "#### \"Users are similar when they comment the same articles (or articles of the same ressort)\"\n",
    "\n",
    "Todo: aggregate postings based on author and target (e.g., article, channel, ressort). Either count or just stay binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Posting</th>\n",
       "      <th>PostingCreatedAt</th>\n",
       "      <th>PostingHeadline</th>\n",
       "      <th>PostingComment</th>\n",
       "      <th>UserCommunityName</th>\n",
       "      <th>ID_Article</th>\n",
       "      <th>ArticleChannel</th>\n",
       "      <th>ArticleRessortName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1041073586</td>\n",
       "      <td>2019-05-01 18:21:15.127</td>\n",
       "      <td>Das hat gestern bereits der Voggenhuber angefü...</td>\n",
       "      <td>schieder hatte dem inhaltlich nichts entgegenz...</td>\n",
       "      <td>Ravenspower</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1041073839</td>\n",
       "      <td>2019-05-01 18:28:22.040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...und meinen Bezirk bekommst du als Erbe mit.</td>\n",
       "      <td>AlphaRomeo</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041073872</td>\n",
       "      <td>2019-05-01 18:29:05.533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nein, bei der ÖVP/FPÖ genauso passiert. Ich wo...</td>\n",
       "      <td>Hpolditsch</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1041080734</td>\n",
       "      <td>2019-05-01 22:37:56.010</td>\n",
       "      <td>Sie haben doch nichts gefordert??</td>\n",
       "      <td>sie haben nur die regierung kritisiert. das di...</td>\n",
       "      <td>Ravenspower</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1041080828</td>\n",
       "      <td>2019-05-01 22:42:06.310</td>\n",
       "      <td>Heute wäre der perfekte Tag für die SPÖ gewese...</td>\n",
       "      <td>ihr noch nicht erfülltes versprechen, den silb...</td>\n",
       "      <td>Ravenspower</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395929</th>\n",
       "      <td>1042380731</td>\n",
       "      <td>2019-06-04 08:54:54.177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vermutlich gar keines...mir ist jedenfalls kei...</td>\n",
       "      <td>404 not found</td>\n",
       "      <td>2000103620997</td>\n",
       "      <td>User</td>\n",
       "      <td>Off-Topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395930</th>\n",
       "      <td>1042381030</td>\n",
       "      <td>2019-06-04 09:04:32.037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*winkt dankbar zur Gödelnummer* Du bist echt d...</td>\n",
       "      <td>404 not found</td>\n",
       "      <td>2000103620997</td>\n",
       "      <td>User</td>\n",
       "      <td>Off-Topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395931</th>\n",
       "      <td>1042381528</td>\n",
       "      <td>2019-06-04 09:22:54.473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Die sind noch in Arbeit, aber der Surface läuf...</td>\n",
       "      <td>404 not found</td>\n",
       "      <td>2000103620997</td>\n",
       "      <td>User</td>\n",
       "      <td>Off-Topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395932</th>\n",
       "      <td>1042381793</td>\n",
       "      <td>2019-06-04 09:31:45.077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ich versteh das überhaupt nicht, warum so viel...</td>\n",
       "      <td>404 not found</td>\n",
       "      <td>2000103620997</td>\n",
       "      <td>User</td>\n",
       "      <td>Off-Topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395933</th>\n",
       "      <td>1042389523</td>\n",
       "      <td>2019-06-04 13:09:09.613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Das war der erste von vielen, den ich gecheckt...</td>\n",
       "      <td>404 not found</td>\n",
       "      <td>2000103620997</td>\n",
       "      <td>User</td>\n",
       "      <td>Off-Topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>739094 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID_Posting         PostingCreatedAt  \\\n",
       "0       1041073586  2019-05-01 18:21:15.127   \n",
       "1       1041073839  2019-05-01 18:28:22.040   \n",
       "2       1041073872  2019-05-01 18:29:05.533   \n",
       "3       1041080734  2019-05-01 22:37:56.010   \n",
       "4       1041080828  2019-05-01 22:42:06.310   \n",
       "...            ...                      ...   \n",
       "395929  1042380731  2019-06-04 08:54:54.177   \n",
       "395930  1042381030  2019-06-04 09:04:32.037   \n",
       "395931  1042381528  2019-06-04 09:22:54.473   \n",
       "395932  1042381793  2019-06-04 09:31:45.077   \n",
       "395933  1042389523  2019-06-04 13:09:09.613   \n",
       "\n",
       "                                          PostingHeadline  \\\n",
       "0       Das hat gestern bereits der Voggenhuber angefü...   \n",
       "1                                                     NaN   \n",
       "2                                                     NaN   \n",
       "3                       Sie haben doch nichts gefordert??   \n",
       "4       Heute wäre der perfekte Tag für die SPÖ gewese...   \n",
       "...                                                   ...   \n",
       "395929                                                NaN   \n",
       "395930                                                NaN   \n",
       "395931                                                NaN   \n",
       "395932                                                NaN   \n",
       "395933                                                NaN   \n",
       "\n",
       "                                           PostingComment UserCommunityName  \\\n",
       "0       schieder hatte dem inhaltlich nichts entgegenz...       Ravenspower   \n",
       "1          ...und meinen Bezirk bekommst du als Erbe mit.        AlphaRomeo   \n",
       "2       Nein, bei der ÖVP/FPÖ genauso passiert. Ich wo...        Hpolditsch   \n",
       "3       sie haben nur die regierung kritisiert. das di...       Ravenspower   \n",
       "4       ihr noch nicht erfülltes versprechen, den silb...       Ravenspower   \n",
       "...                                                   ...               ...   \n",
       "395929  Vermutlich gar keines...mir ist jedenfalls kei...     404 not found   \n",
       "395930  *winkt dankbar zur Gödelnummer* Du bist echt d...     404 not found   \n",
       "395931  Die sind noch in Arbeit, aber der Surface läuf...     404 not found   \n",
       "395932  Ich versteh das überhaupt nicht, warum so viel...     404 not found   \n",
       "395933  Das war der erste von vielen, den ich gecheckt...     404 not found   \n",
       "\n",
       "           ID_Article ArticleChannel ArticleRessortName  \n",
       "0       2000102330973         Inland           Parteien  \n",
       "1       2000102330973         Inland           Parteien  \n",
       "2       2000102330973         Inland           Parteien  \n",
       "3       2000102330973         Inland           Parteien  \n",
       "4       2000102330973         Inland           Parteien  \n",
       "...               ...            ...                ...  \n",
       "395929  2000103620997           User          Off-Topic  \n",
       "395930  2000103620997           User          Off-Topic  \n",
       "395931  2000103620997           User          Off-Topic  \n",
       "395932  2000103620997           User          Off-Topic  \n",
       "395933  2000103620997           User          Off-Topic  \n",
       "\n",
       "[739094 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings[[\"ID_Posting\",\"PostingCreatedAt\",\"PostingHeadline\", \"PostingComment\", \"UserCommunityName\",\"ID_Article\", \"ArticleChannel\", \"ArticleRessortName\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 156. GiB for an array with shape (20967594396,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m votes_with_article_id \u001b[39m=\u001b[39m (votes[votes[\u001b[39m\"\u001b[39m\u001b[39mUserCommunityName\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39misin(selected_users)][[\u001b[39m\"\u001b[39m\u001b[39mUserCommunityName\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mID_Posting\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mVotePositive\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mVoteNegative\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mmerge(postings[[\n\u001b[1;32m      2\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39mID_Posting\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mID_Article\u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39m\"\u001b[39m\u001b[39mPostingCreatedAt\u001b[39m\u001b[39m\"\u001b[39m]], on\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mID_Posting\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[0;32m----> 6\u001b[0m postings_simmilarity \u001b[39m=\u001b[39m (votes_with_article_id\n\u001b[1;32m      7\u001b[0m     \u001b[39m.\u001b[39;49mmerge(votes_with_article_id[[\u001b[39m\"\u001b[39;49m\u001b[39mUserCommunityName\u001b[39;49m\u001b[39m\"\u001b[39;49m,    \u001b[39m\"\u001b[39;49m\u001b[39mID_Article\u001b[39;49m\u001b[39m\"\u001b[39;49m]], on\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mID_Article\u001b[39;49m\u001b[39m\"\u001b[39;49m], how\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minner\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m     \u001b[39m.\u001b[39mquery(\u001b[39m\"\u001b[39m\u001b[39mUserCommunityName_x != UserCommunityName_y\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mID_Article\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     10\u001b[0m     \u001b[39m.\u001b[39mgroupby([\u001b[39m\"\u001b[39m\u001b[39mUserCommunityName_x\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mUserCommunityName_y\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m     \u001b[39m.\u001b[39msum()\n\u001b[1;32m     12\u001b[0m     \u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m     13\u001b[0m     \u001b[39m.\u001b[39msort_values(\u001b[39m\"\u001b[39m\u001b[39mvotes_p_n\u001b[39m\u001b[39m\"\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/anaconda3/envs/sna/lib/python3.10/site-packages/pandas/core/frame.py:9354\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9335\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   9336\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m   9337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9350\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   9351\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   9352\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmerge\u001b[39;00m \u001b[39mimport\u001b[39;00m merge\n\u001b[0;32m-> 9354\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m   9355\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   9356\u001b[0m         right,\n\u001b[1;32m   9357\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m   9358\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m   9359\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m   9360\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m   9361\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m   9362\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m   9363\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   9364\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m   9365\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   9366\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m   9367\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m   9368\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/sna/lib/python3.10/site-packages/pandas/core/reshape/merge.py:122\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m    107\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    108\u001b[0m         left,\n\u001b[1;32m    109\u001b[0m         right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m    121\u001b[0m     )\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/sna/lib/python3.10/site-packages/pandas/core/reshape/merge.py:716\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n\u001b[1;32m    714\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[0;32m--> 716\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_join_info()\n\u001b[1;32m    718\u001b[0m llabels, rlabels \u001b[39m=\u001b[39m _items_overlap_with_suffix(\n\u001b[1;32m    719\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft\u001b[39m.\u001b[39m_info_axis, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright\u001b[39m.\u001b[39m_info_axis, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuffixes\n\u001b[1;32m    720\u001b[0m )\n\u001b[1;32m    722\u001b[0m lindexers \u001b[39m=\u001b[39m {\u001b[39m1\u001b[39m: left_indexer} \u001b[39mif\u001b[39;00m left_indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/sna/lib/python3.10/site-packages/pandas/core/reshape/merge.py:967\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    963\u001b[0m     join_index, right_indexer, left_indexer \u001b[39m=\u001b[39m _left_join_on_index(\n\u001b[1;32m    964\u001b[0m         right_ax, left_ax, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys, sort\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort\n\u001b[1;32m    965\u001b[0m     )\n\u001b[1;32m    966\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 967\u001b[0m     (left_indexer, right_indexer) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_join_indexers()\n\u001b[1;32m    969\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_index:\n\u001b[1;32m    970\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sna/lib/python3.10/site-packages/pandas/core/reshape/merge.py:941\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_join_indexers\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp], npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp]]:\n\u001b[1;32m    940\u001b[0m     \u001b[39m\"\"\"return the join indexers\"\"\"\u001b[39;00m\n\u001b[0;32m--> 941\u001b[0m     \u001b[39mreturn\u001b[39;00m get_join_indexers(\n\u001b[1;32m    942\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft_join_keys, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright_join_keys, sort\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msort, how\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhow\n\u001b[1;32m    943\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/sna/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1513\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[0;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m join_func \u001b[39m=\u001b[39m {\n\u001b[1;32m   1504\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minner\u001b[39m\u001b[39m\"\u001b[39m: libjoin\u001b[39m.\u001b[39minner_join,\n\u001b[1;32m   1505\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m: libjoin\u001b[39m.\u001b[39mleft_outer_join,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mouter\u001b[39m\u001b[39m\"\u001b[39m: libjoin\u001b[39m.\u001b[39mfull_outer_join,\n\u001b[1;32m   1510\u001b[0m }[how]\n\u001b[1;32m   1512\u001b[0m \u001b[39m# error: Cannot call function of unknown type\u001b[39;00m\n\u001b[0;32m-> 1513\u001b[0m \u001b[39mreturn\u001b[39;00m join_func(lkey, rkey, count, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sna/lib/python3.10/site-packages/pandas/_libs/join.pyx:48\u001b[0m, in \u001b[0;36mpandas._libs.join.inner_join\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 156. GiB for an array with shape (20967594396,) and data type int64"
     ]
    }
   ],
   "source": [
    "votes_with_article_id = (votes[votes[\"UserCommunityName\"].isin(selected_users)][[\"UserCommunityName\", \"ID_Posting\", \"VotePositive\", \"VoteNegative\"]].merge(postings[[\n",
    "               \"ID_Posting\", \"ID_Article\",  \"PostingCreatedAt\"]], on=[\"ID_Posting\"]))\n",
    "\n",
    "\n",
    "\n",
    "postings_simmilarity = (votes_with_article_id\n",
    "    .merge(votes_with_article_id[[\"UserCommunityName\",    \"ID_Article\"]], on=[\"ID_Article\"], how=\"inner\")\n",
    "    .query(\"UserCommunityName_x != UserCommunityName_y\")\n",
    "    .drop(columns=[\"ID_Article\"])\n",
    "    .groupby([\"UserCommunityName_x\", \"UserCommunityName_y\"])\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .sort_values(\"votes_p_n\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CommunityIdentity</th>\n",
       "      <th>ID_Posting</th>\n",
       "      <th>VotePositive</th>\n",
       "      <th>VoteNegative</th>\n",
       "      <th>ID_Article</th>\n",
       "      <th>PostingCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>675862</td>\n",
       "      <td>1041076570</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 20:04:07.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>689023</td>\n",
       "      <td>1041076570</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 20:04:07.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>606376</td>\n",
       "      <td>1041076570</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 20:04:07.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24810</td>\n",
       "      <td>1041076745</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000102349577</td>\n",
       "      <td>2019-05-01 20:11:30.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>673781</td>\n",
       "      <td>1041076745</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000102349577</td>\n",
       "      <td>2019-05-01 20:11:30.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824979</th>\n",
       "      <td>694312</td>\n",
       "      <td>1042273551</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000103963403</td>\n",
       "      <td>2019-05-31 21:15:14.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824980</th>\n",
       "      <td>220003</td>\n",
       "      <td>1042275757</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000103475778</td>\n",
       "      <td>2019-05-31 22:47:05.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824981</th>\n",
       "      <td>220003</td>\n",
       "      <td>1042279910</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000103475778</td>\n",
       "      <td>2019-06-01 08:25:35.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824982</th>\n",
       "      <td>654563</td>\n",
       "      <td>1042304669</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000104167823</td>\n",
       "      <td>2019-06-01 22:32:21.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824983</th>\n",
       "      <td>503247</td>\n",
       "      <td>1042366280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000104027083</td>\n",
       "      <td>2019-06-03 18:32:50.180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3824984 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID_CommunityIdentity  ID_Posting  VotePositive  VoteNegative  \\\n",
       "0                      675862  1041076570             0             1   \n",
       "1                      689023  1041076570             0             1   \n",
       "2                      606376  1041076570             1             0   \n",
       "3                       24810  1041076745             1             0   \n",
       "4                      673781  1041076745             1             0   \n",
       "...                       ...         ...           ...           ...   \n",
       "3824979                694312  1042273551             1             0   \n",
       "3824980                220003  1042275757             0             1   \n",
       "3824981                220003  1042279910             0             1   \n",
       "3824982                654563  1042304669             1             0   \n",
       "3824983                503247  1042366280             1             0   \n",
       "\n",
       "            ID_Article         PostingCreatedAt  \n",
       "0        2000102330973  2019-05-01 20:04:07.580  \n",
       "1        2000102330973  2019-05-01 20:04:07.580  \n",
       "2        2000102330973  2019-05-01 20:04:07.580  \n",
       "3        2000102349577  2019-05-01 20:11:30.570  \n",
       "4        2000102349577  2019-05-01 20:11:30.570  \n",
       "...                ...                      ...  \n",
       "3824979  2000103963403  2019-05-31 21:15:14.137  \n",
       "3824980  2000103475778  2019-05-31 22:47:05.570  \n",
       "3824981  2000103475778  2019-06-01 08:25:35.210  \n",
       "3824982  2000104167823  2019-06-01 22:32:21.463  \n",
       "3824983  2000104027083  2019-06-03 18:32:50.180  \n",
       "\n",
       "[3824984 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes_with_article_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()\n",
    "graph.add_nodes_from(votes_with_article_id[\"UserCommunityName\"].unique())\n",
    "graph.add_nodes_from(votes_with_article_id[\"ID_Article\"].unique())\n",
    "graph.add_edges_from(list(map(tuple, votes_with_article_id[[\"UserCommunityName\", \"ID_Article\"]].values)))\n",
    "graph = graph.to_undirected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "still takes ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 %\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mif\u001b[39;00m uu_tuple[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m uu_tuple[\u001b[39m1\u001b[39m]:\n\u001b[1;32m     14\u001b[0m     uu_tuple \u001b[39m=\u001b[39m (uu_tuple[\u001b[39m1\u001b[39m], uu_tuple[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m \u001b[39mif\u001b[39;00m uu_tuple \u001b[39min\u001b[39;00m data:\n\u001b[1;32m     16\u001b[0m     data[uu_tuple] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.sparse import  csr_matrix\n",
    "import itertools\n",
    "\n",
    "tuples = []\n",
    "data = []\n",
    "data = {}\n",
    "article_ids = votes_with_article_id[\"ID_Article\"].unique()\n",
    "for idx, article in enumerate(article_ids):\n",
    "    print(int((idx/len(article_ids))*100), \"%\", end=\"\\r\")\n",
    "    users_commented =list(graph.neighbors(article))\n",
    "    for uu_tuple in itertools.product(users_commented, users_commented):\n",
    "        if uu_tuple[0] != uu_tuple[1]:\n",
    "            if uu_tuple[0] > uu_tuple[1]:\n",
    "                uu_tuple = (uu_tuple[1], uu_tuple[0])\n",
    "            if uu_tuple in data:\n",
    "                data[uu_tuple] += 1\n",
    "            else:\n",
    "                data[uu_tuple] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "invalid input format",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/sna/lib/python3.10/site-packages/scipy/sparse/_coo.py:141\u001b[0m, in \u001b[0;36mcoo_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     obj, (row, col) \u001b[39m=\u001b[39m arg1\n\u001b[1;32m    142\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_users \u001b[39m=\u001b[39m votes_with_article_id[\u001b[39m\"\u001b[39m\u001b[39mID_CommunityIdentity\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[0;32m----> 2\u001b[0m csr_matrix((data\u001b[39m.\u001b[39;49mvalues(), data\u001b[39m.\u001b[39;49mkeys()), shape\u001b[39m=\u001b[39;49m(num_users,num_users))\n",
      "File \u001b[0;32m~/anaconda3/envs/sna/lib/python3.10/site-packages/scipy/sparse/_compressed.py:53\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(arg1) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m     51\u001b[0m         \u001b[39m# (data, ij) format\u001b[39;00m\n\u001b[1;32m     52\u001b[0m         other \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(\n\u001b[0;32m---> 53\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coo_container(arg1, shape\u001b[39m=\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_self(other)\n\u001b[1;32m     56\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(arg1) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m     57\u001b[0m         \u001b[39m# (data, indices, indptr) format\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sna/lib/python3.10/site-packages/scipy/sparse/_coo.py:143\u001b[0m, in \u001b[0;36mcoo_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    141\u001b[0m     obj, (row, col) \u001b[39m=\u001b[39m arg1\n\u001b[1;32m    142\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39minvalid input format\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(row) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(col) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid input format"
     ]
    }
   ],
   "source": [
    "num_users = votes_with_article_id[\"UserCommunityName\"].unique()\n",
    "csr_matrix((data.values(), data.keys()), shape=(num_users,num_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vote similarity\n",
    "#### \"Users are similar when they upvote posts of the same author\"\n",
    "Too complex -> jupyter kernel dies TODO remove or try on jupyerlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_author_posting_author = pd.merge(votes[[\"UserCommunityName\", \"ID_Posting\", \"VotePositive\", \"VoteNegative\"]], postings[[\n",
    "               \"ID_Posting\", \"UserCommunityName\",  \"PostingCreatedAt\"]], on=[\"ID_Posting\"])\\\n",
    "                .rename(columns={\"UserCommunityName_x\": \"vote_author\", \"UserCommunityName_y\": \"posting_author\"})\\\n",
    "                        .groupby([\"vote_author\", \"posting_author\"]).sum().reset_index()\n",
    "\n",
    "# same vote authors and posting authors\n",
    "number_of_votes_per_author = vote_author_posting_author.assign(votes = lambda x: x.VotePositive + x.VoteNegative).groupby([\"posting_author\"])[\"votes\"].sum()\n",
    "influental_authors = number_of_votes_per_author[number_of_votes_per_author> 5].reset_index()[\"posting_author\"]\n",
    "print(f\"Proportion of authors having more than 5 votes: {influental_authors.shape[0]/number_of_votes_per_author.shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAUTION!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_simmilarity = (vote_author_posting_author.assign(votes_p_n = lambda x: - x.VoteNegative + x.VotePositive)\n",
    "    [[\"vote_author\",    \"posting_author\", \"votes_p_n\"]]\n",
    "    .merge(vote_author_posting_author[[\"vote_author\",    \"posting_author\"]], on=[\"posting_author\"], how=\"inner\")\n",
    "    .query(\"vote_authory_x != vote_author_y\")\n",
    "    .drop(columns=[\"ID_Posting\"])\n",
    "    .groupby([\"vote_author_x\", \"vote_author_y\"])\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .sort_values(\"votes_p_n\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative same downvotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive same upvotes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Users are similar when the use similar words\n",
    "idk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('sna')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd8ef2f58c32900e0da76c82afad42ef1f21edae6af587b6cfe674f3d8a65feb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
