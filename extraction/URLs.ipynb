{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666bb1d6",
   "metadata": {},
   "source": [
    "# Extracting URLs from User Postings\n",
    "\n",
    "In the following we load in the Postings datasets and extract the URLs and domains from them. Then we analyse the results and show how to merge the extracted data with the original dataset. First making the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63796452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urlparse # for parsing the domains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d95b4",
   "metadata": {},
   "source": [
    "<b>Loading datasets</b>\n",
    "\n",
    "Importing the datasets from the input/ directory. These dataset do not exist in the GitLab repository currently. \n",
    "\n",
    "It turns out this directory is in .gitignore. I believe the files are meant to be copied from the repository to our local directories because the csv files are a bit large and it would take longer to clone the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f77bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "postings1 = pd.read_csv(\"../input/Postings_01052019_15052019.csv\", delimiter=\";\")\n",
    "postings2 = pd.read_csv(\"../input/Postings_16052019_31052019.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faef162",
   "metadata": {},
   "source": [
    "Merging the two columns together in order to make filtering easier, skipping the need for a loop and keeping the code more simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5cfdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging headline and comment\n",
    "comments1 = postings1[\"PostingHeadline\"].fillna('') + \" \" + postings1[\"PostingComment\"]\n",
    "comments2 = postings2[\"PostingHeadline\"].fillna('') + \" \" + postings2[\"PostingComment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d98ec",
   "metadata": {},
   "source": [
    "<b>Extracting URLs and domains</b>\n",
    "\n",
    "Copied the Regex from an online resource. This will not parse a url unless it starts with http(s)://. I believe this should be fine because I expect every proper URL link to include those.\n",
    "\n",
    "In order to avoid making the handling of the dataset unnecessarily complicated, I'm assuming that there can be no more than one URL in a posting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f92925",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = comments1.str.extract(r'(https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b(?:[-a-zA-Z0-9()@:%_\\+.~#?&\\/=]*))').dropna()[0]\n",
    "url2 = comments2.str.extract(r'(https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b(?:[-a-zA-Z0-9()@:%_\\+.~#?&\\/=]*))').dropna()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f59b074",
   "metadata": {},
   "source": [
    "The urlparse() function from urllib.parse parses domains from urls. I've changed the output a little bit because urlparse would parse https://www.google.com/abc as www.google.com and https://google.com/abc as google.com, and thus those would be considered different domains. I believe that it makes sense to combine these as one, and thus I'm skipping everything before the final two '.'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04232288",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain1 = url1.apply(lambda x: \".\".join(urlparse(x).netloc.split(\".\")[-2:]))\n",
    "domain2 = url2.apply(lambda x: \".\".join(urlparse(x).netloc.split(\".\")[-2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d258b1",
   "metadata": {},
   "source": [
    "I also attempted to retrieve the titles from the links but the following code takes forever to retrieve the titles.\n",
    "\n",
    "If it makes sense to extract this information at some later point, I'll try and improve the code, but I'm leaving it out now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0015257",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I tried to retrieve the titles for the URLs but it took forever. \n",
    "## I'll retry and improve this section at some later point if that makes sense.\n",
    "# import requests\n",
    "# def get_title(url):\n",
    "#     try:\n",
    "#         headers = {'headers':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:51.0) Gecko/20100101 Firefox/51.0'}\n",
    "#         n = requests.get(url, headers=headers)\n",
    "#         al = n.text\n",
    "#         return al[al.find('<title>') + 7 : al.find('</title>')]\n",
    "#     except:\n",
    "#         return None\n",
    "# titles1 = url1.apply(lambda x: get_title(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a962ae6",
   "metadata": {},
   "source": [
    "Merging url and domain data into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb198bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1[\"url\"] = url1\n",
    "df1[\"domain\"] = domain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e750018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2[\"url\"] = url2\n",
    "df2[\"domain\"] = domain2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede7778",
   "metadata": {},
   "source": [
    "# Analyzing the extracted data\n",
    "\n",
    "Let's first take a look at the sample of the data that was extracted to get a feel of the data that was extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec85e8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.youtube.com/watch?v=yiJ-sdjn2Zg</td>\n",
       "      <td>youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.kleinezeitung.at/politik/innenpoli...</td>\n",
       "      <td>kleinezeitung.at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://derstandard.at/1369363252227/Vom-hungr...</td>\n",
       "      <td>derstandard.at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>https://wahlkabine.at/eu2019/wahlkabine/1</td>\n",
       "      <td>wahlkabine.at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>https://derstandard.at/2000102257779/Vom-Umgan...</td>\n",
       "      <td>derstandard.at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343033</th>\n",
       "      <td>https://veganova.at/produkte/hag-capisco-mit-w...</td>\n",
       "      <td>veganova.at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343037</th>\n",
       "      <td>https://www.tagesschau.de/ausland/panamapapers...</td>\n",
       "      <td>tagesschau.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343044</th>\n",
       "      <td>https://www.heise.de/tp/features/EU-Kommission...</td>\n",
       "      <td>heise.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343046</th>\n",
       "      <td>https://derstandard.at/2000041068013/Wie-viel-...</td>\n",
       "      <td>derstandard.at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343047</th>\n",
       "      <td>https://de.wikipedia.org/wiki/Jean-Claude_Junc...</td>\n",
       "      <td>wikipedia.org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11716 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url            domain\n",
       "0             https://www.youtube.com/watch?v=yiJ-sdjn2Zg       youtube.com\n",
       "15      https://www.kleinezeitung.at/politik/innenpoli...  kleinezeitung.at\n",
       "25      https://derstandard.at/1369363252227/Vom-hungr...    derstandard.at\n",
       "32              https://wahlkabine.at/eu2019/wahlkabine/1     wahlkabine.at\n",
       "44      https://derstandard.at/2000102257779/Vom-Umgan...    derstandard.at\n",
       "...                                                   ...               ...\n",
       "343033  https://veganova.at/produkte/hag-capisco-mit-w...       veganova.at\n",
       "343037  https://www.tagesschau.de/ausland/panamapapers...     tagesschau.de\n",
       "343044  https://www.heise.de/tp/features/EU-Kommission...          heise.de\n",
       "343046  https://derstandard.at/2000041068013/Wie-viel-...    derstandard.at\n",
       "343047  https://de.wikipedia.org/wiki/Jean-Claude_Junc...     wikipedia.org\n",
       "\n",
       "[11716 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d6724",
   "metadata": {},
   "source": [
    "<b>Shares of postings with URLs</b>\n",
    "\n",
    "As to be expected, not all the postings have a URL in them. The following code chunks show that roughly 3% of the posts have urls in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68dc4927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03732755599452003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"url\"].count()/comments1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bc5efb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03171388713862375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"url\"].count()/comments2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d61f1",
   "metadata": {},
   "source": [
    "<b>Unique URLs and unique domains</b>\n",
    "\n",
    "In the code chunks below we can see how only 10% of the posted URLs repeat, while it's true for 33% of the domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3d2dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8983776251617398"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"url\"].value_counts()[df1[\"url\"].value_counts()==1].count()/df1[\"url\"].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95773887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6748878923766816"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"domain\"].value_counts()[df1[\"domain\"].value_counts()==1].count()/df1[\"domain\"].value_counts().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404203f7",
   "metadata": {},
   "source": [
    "# Saving the extracted data\n",
    "\n",
    "Saving the extracted data so it can be loaded in a separate notebook or script without having to run the code in this file every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d754b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"URLs-Postings_01052019_15052019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd1b2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"URLs-Postings_16052019_31052019.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc59073",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5058526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for loading in the data for the first Postings file\n",
    "urls_df_1 = pd.read_csv(\"URLs-Postings_01052019_15052019.csv\").set_index('Unnamed: 0')\n",
    "urls_df_1.index.names = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "060bc963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for loading in the data for the second Postings file\n",
    "urls_df_2 = pd.read_csv(\"URLs-Postings_16052019_31052019.csv\").set_index('Unnamed: 0')\n",
    "urls_df_2.index.names = [None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37915605",
   "metadata": {},
   "source": [
    "<b>Viewing what we loaded in</b>\n",
    "\n",
    "The following is identical to the df1 dataset we have seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c97820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.youtube.com/watch?v=yiJ-sdjn2Zg</td>\n",
       "      <td>youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.kleinezeitung.at/politik/innenpoli...</td>\n",
       "      <td>kleinezeitung.at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://derstandard.at/1369363252227/Vom-hungr...</td>\n",
       "      <td>derstandard.at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>https://wahlkabine.at/eu2019/wahlkabine/1</td>\n",
       "      <td>wahlkabine.at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>https://derstandard.at/2000102257779/Vom-Umgan...</td>\n",
       "      <td>derstandard.at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343033</th>\n",
       "      <td>https://veganova.at/produkte/hag-capisco-mit-w...</td>\n",
       "      <td>veganova.at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343037</th>\n",
       "      <td>https://www.tagesschau.de/ausland/panamapapers...</td>\n",
       "      <td>tagesschau.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343044</th>\n",
       "      <td>https://www.heise.de/tp/features/EU-Kommission...</td>\n",
       "      <td>heise.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343046</th>\n",
       "      <td>https://derstandard.at/2000041068013/Wie-viel-...</td>\n",
       "      <td>derstandard.at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343047</th>\n",
       "      <td>https://de.wikipedia.org/wiki/Jean-Claude_Junc...</td>\n",
       "      <td>wikipedia.org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11716 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url            domain\n",
       "0             https://www.youtube.com/watch?v=yiJ-sdjn2Zg       youtube.com\n",
       "15      https://www.kleinezeitung.at/politik/innenpoli...  kleinezeitung.at\n",
       "25      https://derstandard.at/1369363252227/Vom-hungr...    derstandard.at\n",
       "32              https://wahlkabine.at/eu2019/wahlkabine/1     wahlkabine.at\n",
       "44      https://derstandard.at/2000102257779/Vom-Umgan...    derstandard.at\n",
       "...                                                   ...               ...\n",
       "343033  https://veganova.at/produkte/hag-capisco-mit-w...       veganova.at\n",
       "343037  https://www.tagesschau.de/ausland/panamapapers...     tagesschau.de\n",
       "343044  https://www.heise.de/tp/features/EU-Kommission...          heise.de\n",
       "343046  https://derstandard.at/2000041068013/Wie-viel-...    derstandard.at\n",
       "343047  https://de.wikipedia.org/wiki/Jean-Claude_Junc...     wikipedia.org\n",
       "\n",
       "[11716 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85acd9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_df_1.equals(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "117dd41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_df_2.equals(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4219714a",
   "metadata": {},
   "source": [
    "# Merging data with the original Postings datasets\n",
    "\n",
    "For our task of using URLs as a possible way to measure similarity using the urls they posted, or whether any urls were posted in the first place, we need a user representing the user id. This ID is to be found in the Postings CSV files.\n",
    "\n",
    "The following code merges the Postings CSV files with the urls_df_1 and urls_df_2 dataframes.\n",
    "\n",
    "Remember we have previously loaded in \"Postings_01052019_15052019.csv\" as postings1 and \"Postings_16052019_31052019.csv\" as postings2 as dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a438d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged1 = pd.concat([postings1, urls_df_1], axis=1)\n",
    "merged2 = pd.concat([postings2, urls_df_2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191d2dec",
   "metadata": {},
   "source": [
    "Notice that the merged1 dataframe corresponds to the postings1 dataframe with additional columns \"url\" and \"domain\". \n",
    "\n",
    "The first row includes a URL and thus has some contents. Most other rows have NaN values there because they don't include any URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91184e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Posting</th>\n",
       "      <th>ID_Posting_Parent</th>\n",
       "      <th>ID_CommunityIdentity</th>\n",
       "      <th>PostingHeadline</th>\n",
       "      <th>PostingComment</th>\n",
       "      <th>PostingCreatedAt</th>\n",
       "      <th>ID_Article</th>\n",
       "      <th>ArticlePublishingDate</th>\n",
       "      <th>ArticleTitle</th>\n",
       "      <th>ArticleChannel</th>\n",
       "      <th>ArticleRessortName</th>\n",
       "      <th>UserCommunityName</th>\n",
       "      <th>UserGender</th>\n",
       "      <th>UserCreatedAt</th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1041073586</td>\n",
       "      <td>1.041073e+09</td>\n",
       "      <td>671476</td>\n",
       "      <td>Das hat gestern bereits der Voggenhuber angefü...</td>\n",
       "      <td>schieder hatte dem inhaltlich nichts entgegenz...</td>\n",
       "      <td>2019-05-01 18:21:15.127</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 10:28:57.49</td>\n",
       "      <td>1. Mai in Wien: SPÖ fordert von Strache Rücktritt</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "      <td>Ravenspower</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-14 13:42:28.470</td>\n",
       "      <td>https://www.youtube.com/watch?v=yiJ-sdjn2Zg</td>\n",
       "      <td>youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1041073839</td>\n",
       "      <td>1.041073e+09</td>\n",
       "      <td>566938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...und meinen Bezirk bekommst du als Erbe mit.</td>\n",
       "      <td>2019-05-01 18:28:22.040</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 10:28:57.49</td>\n",
       "      <td>1. Mai in Wien: SPÖ fordert von Strache Rücktritt</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "      <td>AlphaRomeo</td>\n",
       "      <td>m</td>\n",
       "      <td>2015-08-28 17:07:41.110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041073872</td>\n",
       "      <td>1.041069e+09</td>\n",
       "      <td>669286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nein, bei der ÖVP/FPÖ genauso passiert. Ich wo...</td>\n",
       "      <td>2019-05-01 18:29:05.533</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 10:28:57.49</td>\n",
       "      <td>1. Mai in Wien: SPÖ fordert von Strache Rücktritt</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "      <td>Hpolditsch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-06 20:03:42.737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1041080734</td>\n",
       "      <td>1.041080e+09</td>\n",
       "      <td>671476</td>\n",
       "      <td>Sie haben doch nichts gefordert??</td>\n",
       "      <td>sie haben nur die regierung kritisiert. das di...</td>\n",
       "      <td>2019-05-01 22:37:56.010</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 10:28:57.49</td>\n",
       "      <td>1. Mai in Wien: SPÖ fordert von Strache Rücktritt</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "      <td>Ravenspower</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-14 13:42:28.470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1041080828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>671476</td>\n",
       "      <td>Heute wäre der perfekte Tag für die SPÖ gewese...</td>\n",
       "      <td>ihr noch nicht erfülltes versprechen, den silb...</td>\n",
       "      <td>2019-05-01 22:42:06.310</td>\n",
       "      <td>2000102330973</td>\n",
       "      <td>2019-05-01 10:28:57.49</td>\n",
       "      <td>1. Mai in Wien: SPÖ fordert von Strache Rücktritt</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Parteien</td>\n",
       "      <td>Ravenspower</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-14 13:42:28.470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343155</th>\n",
       "      <td>1041171112</td>\n",
       "      <td>1.041171e+09</td>\n",
       "      <td>678438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auch Ihnen besten Dank für Ihre Mühe!  Ich bin...</td>\n",
       "      <td>2019-05-05 11:27:44.477</td>\n",
       "      <td>2000101751957</td>\n",
       "      <td>2019-05-05 10:00:00.00</td>\n",
       "      <td>Österreichische Streamerinnen: \"Als Frau kämpf...</td>\n",
       "      <td>Web</td>\n",
       "      <td>Games</td>\n",
       "      <td>Ando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-15 17:06:45.757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343156</th>\n",
       "      <td>1041171278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>678438</td>\n",
       "      <td>Eindeutig besser</td>\n",
       "      <td>Wie sich die elektronische Spielewelt doch ent...</td>\n",
       "      <td>2019-05-05 11:33:53.610</td>\n",
       "      <td>2000101751957</td>\n",
       "      <td>2019-05-05 10:00:00.00</td>\n",
       "      <td>Österreichische Streamerinnen: \"Als Frau kämpf...</td>\n",
       "      <td>Web</td>\n",
       "      <td>Games</td>\n",
       "      <td>Ando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-15 17:06:45.757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343157</th>\n",
       "      <td>1041434423</td>\n",
       "      <td>1.041420e+09</td>\n",
       "      <td>116630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aha, auch einer, ders nicht lassen kann.... wo...</td>\n",
       "      <td>2019-05-13 21:23:26.487</td>\n",
       "      <td>2000103031040</td>\n",
       "      <td>2019-05-13 12:00:46.94</td>\n",
       "      <td>Nach Großbrand in Wien-Simmering brauchen hund...</td>\n",
       "      <td>Panorama</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>no me hables...</td>\n",
       "      <td>w</td>\n",
       "      <td>2006-04-25 15:49:57.257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343158</th>\n",
       "      <td>1041435327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>687794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hoffentlich sind keine Flüchtlinge unter den t...</td>\n",
       "      <td>2019-05-13 21:57:49.427</td>\n",
       "      <td>2000103031040</td>\n",
       "      <td>2019-05-13 12:00:46.94</td>\n",
       "      <td>Nach Großbrand in Wien-Simmering brauchen hund...</td>\n",
       "      <td>Panorama</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>Afora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-13 21:52:02.820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343159</th>\n",
       "      <td>1041171868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ich hab keine ahnung worum es da geht...</td>\n",
       "      <td>2019-05-05 11:57:11.233</td>\n",
       "      <td>2000101751957</td>\n",
       "      <td>2019-05-05 10:00:00.00</td>\n",
       "      <td>Österreichische Streamerinnen: \"Als Frau kämpf...</td>\n",
       "      <td>Web</td>\n",
       "      <td>Games</td>\n",
       "      <td>tgaog</td>\n",
       "      <td>m</td>\n",
       "      <td>2008-01-21 12:04:22.590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343160 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID_Posting  ID_Posting_Parent  ID_CommunityIdentity  \\\n",
       "0       1041073586       1.041073e+09                671476   \n",
       "1       1041073839       1.041073e+09                566938   \n",
       "2       1041073872       1.041069e+09                669286   \n",
       "3       1041080734       1.041080e+09                671476   \n",
       "4       1041080828                NaN                671476   \n",
       "...            ...                ...                   ...   \n",
       "343155  1041171112       1.041171e+09                678438   \n",
       "343156  1041171278                NaN                678438   \n",
       "343157  1041434423       1.041420e+09                116630   \n",
       "343158  1041435327                NaN                687794   \n",
       "343159  1041171868                NaN                223390   \n",
       "\n",
       "                                          PostingHeadline  \\\n",
       "0       Das hat gestern bereits der Voggenhuber angefü...   \n",
       "1                                                     NaN   \n",
       "2                                                     NaN   \n",
       "3                       Sie haben doch nichts gefordert??   \n",
       "4       Heute wäre der perfekte Tag für die SPÖ gewese...   \n",
       "...                                                   ...   \n",
       "343155                                                NaN   \n",
       "343156                                   Eindeutig besser   \n",
       "343157                                                NaN   \n",
       "343158                                                NaN   \n",
       "343159                                                NaN   \n",
       "\n",
       "                                           PostingComment  \\\n",
       "0       schieder hatte dem inhaltlich nichts entgegenz...   \n",
       "1          ...und meinen Bezirk bekommst du als Erbe mit.   \n",
       "2       Nein, bei der ÖVP/FPÖ genauso passiert. Ich wo...   \n",
       "3       sie haben nur die regierung kritisiert. das di...   \n",
       "4       ihr noch nicht erfülltes versprechen, den silb...   \n",
       "...                                                   ...   \n",
       "343155  Auch Ihnen besten Dank für Ihre Mühe!  Ich bin...   \n",
       "343156  Wie sich die elektronische Spielewelt doch ent...   \n",
       "343157  aha, auch einer, ders nicht lassen kann.... wo...   \n",
       "343158  Hoffentlich sind keine Flüchtlinge unter den t...   \n",
       "343159           ich hab keine ahnung worum es da geht...   \n",
       "\n",
       "               PostingCreatedAt     ID_Article   ArticlePublishingDate  \\\n",
       "0       2019-05-01 18:21:15.127  2000102330973  2019-05-01 10:28:57.49   \n",
       "1       2019-05-01 18:28:22.040  2000102330973  2019-05-01 10:28:57.49   \n",
       "2       2019-05-01 18:29:05.533  2000102330973  2019-05-01 10:28:57.49   \n",
       "3       2019-05-01 22:37:56.010  2000102330973  2019-05-01 10:28:57.49   \n",
       "4       2019-05-01 22:42:06.310  2000102330973  2019-05-01 10:28:57.49   \n",
       "...                         ...            ...                     ...   \n",
       "343155  2019-05-05 11:27:44.477  2000101751957  2019-05-05 10:00:00.00   \n",
       "343156  2019-05-05 11:33:53.610  2000101751957  2019-05-05 10:00:00.00   \n",
       "343157  2019-05-13 21:23:26.487  2000103031040  2019-05-13 12:00:46.94   \n",
       "343158  2019-05-13 21:57:49.427  2000103031040  2019-05-13 12:00:46.94   \n",
       "343159  2019-05-05 11:57:11.233  2000101751957  2019-05-05 10:00:00.00   \n",
       "\n",
       "                                             ArticleTitle ArticleChannel  \\\n",
       "0       1. Mai in Wien: SPÖ fordert von Strache Rücktritt         Inland   \n",
       "1       1. Mai in Wien: SPÖ fordert von Strache Rücktritt         Inland   \n",
       "2       1. Mai in Wien: SPÖ fordert von Strache Rücktritt         Inland   \n",
       "3       1. Mai in Wien: SPÖ fordert von Strache Rücktritt         Inland   \n",
       "4       1. Mai in Wien: SPÖ fordert von Strache Rücktritt         Inland   \n",
       "...                                                   ...            ...   \n",
       "343155  Österreichische Streamerinnen: \"Als Frau kämpf...            Web   \n",
       "343156  Österreichische Streamerinnen: \"Als Frau kämpf...            Web   \n",
       "343157  Nach Großbrand in Wien-Simmering brauchen hund...       Panorama   \n",
       "343158  Nach Großbrand in Wien-Simmering brauchen hund...       Panorama   \n",
       "343159  Österreichische Streamerinnen: \"Als Frau kämpf...            Web   \n",
       "\n",
       "       ArticleRessortName UserCommunityName UserGender  \\\n",
       "0                Parteien       Ravenspower        NaN   \n",
       "1                Parteien        AlphaRomeo          m   \n",
       "2                Parteien        Hpolditsch        NaN   \n",
       "3                Parteien       Ravenspower        NaN   \n",
       "4                Parteien       Ravenspower        NaN   \n",
       "...                   ...               ...        ...   \n",
       "343155              Games              Ando        NaN   \n",
       "343156              Games              Ando        NaN   \n",
       "343157         Österreich   no me hables...          w   \n",
       "343158         Österreich             Afora        NaN   \n",
       "343159              Games             tgaog          m   \n",
       "\n",
       "                  UserCreatedAt                                          url  \\\n",
       "0       2018-04-14 13:42:28.470  https://www.youtube.com/watch?v=yiJ-sdjn2Zg   \n",
       "1       2015-08-28 17:07:41.110                                          NaN   \n",
       "2       2018-03-06 20:03:42.737                                          NaN   \n",
       "3       2018-04-14 13:42:28.470                                          NaN   \n",
       "4       2018-04-14 13:42:28.470                                          NaN   \n",
       "...                         ...                                          ...   \n",
       "343155  2018-08-15 17:06:45.757                                          NaN   \n",
       "343156  2018-08-15 17:06:45.757                                          NaN   \n",
       "343157  2006-04-25 15:49:57.257                                          NaN   \n",
       "343158  2019-02-13 21:52:02.820                                          NaN   \n",
       "343159  2008-01-21 12:04:22.590                                          NaN   \n",
       "\n",
       "             domain  \n",
       "0       youtube.com  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "...             ...  \n",
       "343155          NaN  \n",
       "343156          NaN  \n",
       "343157          NaN  \n",
       "343158          NaN  \n",
       "343159          NaN  \n",
       "\n",
       "[343160 rows x 16 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
